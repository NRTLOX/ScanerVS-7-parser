import os
import re
import tempfile
import json
import threading
import requests
import openpyxl
from ttkbootstrap.widgets import Checkbutton
import pandas as pd
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from deep_translator import GoogleTranslator
from tkinterdnd2 import TkinterDnD, DND_FILES
import tkinter as tk
from threading import Lock
from tkinter import StringVar, filedialog
from ttkbootstrap import Style
from ttkbootstrap.widgets import Button, Label, Frame, Progressbar, Combobox

GITHUB_TOKEN = ""  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
MAX_WORKERS = 2  # –ß–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è GitHub API
SEARCH_URL = "https://api.github.com/search/repositories"
HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

cache_lock = Lock()

CACHE_FILE = "updates_cache.json"
CONFIG_FILE = "config.json"
# --- –ü–∞—Ä—Å–µ—Ä—ã HTML-—Ñ–∞–π–ª–æ–≤ (oval, astra, fstec) ---

def parse_html_oval(html_path, xlsx_path):
    with open(html_path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f, "html.parser")

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–£—è–∑–≤–∏–º–æ—Å—Ç–∏"
    ws.append(["CVE_ID", "BDU_ID", "CVE_URL", "BDU_URL"])

    for tr in soup.find_all("tr", class_=re.compile("^resultbad")):
        cve_id, bdu_id, cve_url, bdu_url = "", "", "", ""
        for link in tr.find_all("a"):
            href = link.get("href", "")
            text = link.text.strip()
            if "bdu.fstec.ru" in href:
                bdu_id = text
                bdu_url = href
            elif "cve.mitre.org" in href:
                cve_id = text
                cve_url = href
        ws.append([cve_id, bdu_id, cve_url, bdu_url])

    wb.save(xlsx_path)
    return xlsx_path

def parse_html_astra(html_path, xlsx_path):
    with open(html_path, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f, 'html.parser')

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–£—è–∑–≤–∏–º–æ—Å—Ç–∏"
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü "–ü–∞–∫–µ—Ç"
    ws.append(['–ù–æ–º–µ—Ä CVE', '–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (BDU)', '–ü–∞–∫–µ—Ç', '–û–ø–∏—Å–∞–Ω–∏–µ', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—Å—Å—ã–ª–∫–∏)', '–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏'])

    for h3 in soup.find_all('h3', class_='header'):
        header_text = h3.get_text(strip=True)
        if header_text.startswith('2.4.') and 'CVE-' in header_text:
            cve_number = next((p for p in header_text.split() if p.startswith('CVE-')), None)
            table = h3.find_next_sibling('table', class_='table-vulnerabilities')
            if not table:
                continue

            data = {
                '–ù–æ–º–µ—Ä CVE': cve_number, 
                '–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã': '', 
                '–ü–∞–∫–µ—Ç': '',  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è –ø–∞–∫–µ—Ç–∞
                '–û–ø–∏—Å–∞–Ω–∏–µ': '', 
                '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': [], 
                '–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏': ''
            }
            inside_recommendations = False

            for row in table.find_all('tr', class_='table-vulnerabilities__row'):
                cells = row.find_all('td', class_='table-vulnerabilities__cell')

                if len(cells) >= 1 and '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏' in cells[0].get_text(strip=True).lower():
                    inside_recommendations = True
                    continue

                if inside_recommendations:
                    link_tag = row.find('a')
                    if link_tag:
                        data['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'].append(link_tag['href'])
                        continue
                    else:
                        inside_recommendations = False

                if len(cells) >= 3:
                    key = cells[0].get_text(strip=True).lower()
                    value = cells[-1].get_text(strip=True)
                    if key == '—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã':
                        bdu = [x.strip() for x in value.split(',') if x.strip().startswith('BDU:')]
                        data['–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã'] = ', '.join(bdu)
                    elif key == '—É—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏':
                        data['–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏'] = value
                    elif key == '–æ–ø–∏—Å–∞–Ω–∏–µ':
                        data['–û–ø–∏—Å–∞–Ω–∏–µ'] = value
                    elif key == '–ø–æ/–ø–∞–∫–µ—Ç' or key == '–ø–∞–∫–µ—Ç':  # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–∫–µ—Ç–∞
                        data['–ü–∞–∫–µ—Ç'] = value

            ws.append([
                data['–ù–æ–º–µ—Ä CVE'], 
                data['–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã'], 
                data['–ü–∞–∫–µ—Ç'],  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç –≤ —Å—Ç—Ä–æ–∫—É
                data['–û–ø–∏—Å–∞–Ω–∏–µ'], 
                ', '.join(data['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏']), 
                data['–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏']
            ])

    wb.save(xlsx_path)
    return xlsx_path

def parse_html_fstec(html_path, xlsx_path):
    with open(html_path, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f, 'html.parser')

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–£—è–∑–≤–∏–º–æ—Å—Ç–∏"
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü "–ü–∞–∫–µ—Ç"
    ws.append(['–ù–æ–º–µ—Ä CVE', '–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (CVE)', '–ü–∞–∫–µ—Ç', '–û–ø–∏—Å–∞–Ω–∏–µ', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—Å—Å—ã–ª–∫–∏)', '–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏'])

    for h3 in soup.find_all('h3', class_='header'):
        header_text = h3.get_text(strip=True)
        if header_text.startswith('2.4.') and 'BDU:' in header_text:
            bdu_number = next((p for p in header_text.split() if p.startswith('BDU:')), None)
            table = h3.find_next_sibling('table', class_='table-vulnerabilities')
            if not table:
                continue

            data = {
                '–ù–æ–º–µ—Ä CVE': bdu_number, 
                '–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã': '', 
                '–ü–∞–∫–µ—Ç': '',  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è –ø–∞–∫–µ—Ç–∞
                '–û–ø–∏—Å–∞–Ω–∏–µ': '', 
                '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': [], 
                '–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏': ''
            }
            inside_recommendations = False

            for row in table.find_all('tr', class_='table-vulnerabilities__row'):
                cells = row.find_all('td', class_='table-vulnerabilities__cell')

                if len(cells) >= 1 and '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏' in cells[0].get_text(strip=True).lower():
                    inside_recommendations = True
                    continue

                if inside_recommendations:
                    link_tag = row.find('a')
                    if link_tag:
                        data['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'].append(link_tag['href'])
                        continue
                    else:
                        inside_recommendations = False

                if len(cells) >= 3:
                    key = cells[0].get_text(strip=True).lower()
                    value = cells[-1].get_text(strip=True)
                    if key == '—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã':
                        cve = [x.strip() for x in value.split(',') if x.strip().startswith('CVE-')]
                        data['–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã'] = ', '.join(cve)
                    elif key == '—É—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏':
                        data['–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏'] = value
                    elif key == '–æ–ø–∏—Å–∞–Ω–∏–µ':
                        data['–û–ø–∏—Å–∞–Ω–∏–µ'] = value
                    elif key == '–ø–æ/–ø–∞–∫–µ—Ç' or key == '–ø–∞–∫–µ—Ç':  # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–∫–µ—Ç–∞
                        data['–ü–∞–∫–µ—Ç'] = value

            ws.append([
                data['–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã'], 
                data['–ù–æ–º–µ—Ä CVE'], 
                data['–ü–∞–∫–µ—Ç'],  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç –≤ —Å—Ç—Ä–æ–∫—É
                data['–û–ø–∏—Å–∞–Ω–∏–µ'], 
                ', '.join(data['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏']), 
                data['–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏']
            ])

    wb.save(xlsx_path)
    return xlsx_path

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def collect_rows_by_cve(file_path, cve_column_index):
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active
    rows, seen = [], set()
    header = None
    for i, row in enumerate(ws.iter_rows(values_only=True)):
        if i == 0:
            header = row
            continue
        cve = str(row[cve_column_index]).strip() if row[cve_column_index] else ''
        if cve and cve not in seen:
            seen.add(cve)
            rows.append((cve, row))
    return header, rows, seen

def merge_cve_rows(output_file, closed_file=None, packages_file=None, *files):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ Excel —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª.
    files: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ xlsx —Ñ–∞–π–ª–∞–º (–æ—Ç 1 –¥–æ 3 —à—Ç—É–∫).
    –û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å—Ç–æ–ª–±—Ü–æ–≤:
      - OVAL-—Ñ–∞–π–ª: CVE –≤ –∫–æ–ª–æ–Ω–∫–µ index=2
      - ASTRA/FSTEC: CVE –≤ –∫–æ–ª–æ–Ω–∫–µ index=0, –ø–∞–∫–µ—Ç –≤ index=2
    """
    def load_packages_from_file(file_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–∫–µ—Ç—ã –∏ –∏—Ö –≤–µ—Ä—Å–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        packages = set()
        if not file_path or not os.path.exists(file_path):
            return packages
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split(';')
                    if len(parts) >= 1:
                        name = parts[0].split(':')[0]  # –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å
                        packages.add(name.lower())  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –ø–∞–∫–µ—Ç–æ–≤: {e}")
        return packages

    def collect_cves_from_file(file_path, cve_col_idx):
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ CVE –∏–∑ —Ñ–∞–π–ª–∞ –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ"""
        wb = openpyxl.load_workbook(file_path)
        ws = wb.active
        cves = set()
        for row in ws.iter_rows(values_only=True, min_row=2):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            cve = str(row[cve_col_idx]).strip() if row[cve_col_idx] else ''
            if cve:
                cves.add(cve)
        return cves

    if not files:
        raise ValueError("–ù–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    packages = load_packages_from_file(packages_file) if packages_file else set()

    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–µ—Ä–µ–º –≤—Å–µ CVE –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    file_cves = {}
    for file_path in files:
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–Ω–µ –ø–æ –∏–º–µ–Ω–∏)
            wb = openpyxl.load_workbook(file_path)
            ws = wb.active
            first_row = next(ws.iter_rows(values_only=True))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ —Å CVE
            if "–ù–æ–º–µ—Ä CVE" in first_row or "CVE_ID" in first_row:
                cve_col_idx = first_row.index("–ù–æ–º–µ—Ä CVE") if "–ù–æ–º–µ—Ä CVE" in first_row else first_row.index("CVE_ID")
            else:
                # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –≤ –ø–µ—Ä–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ –µ—Å—Ç—å CVE - —ç—Ç–æ ASTRA/FSTEC, –∏–Ω–∞—á–µ OVAL
                sample_cve = next((str(cell).strip() for cell in first_row if str(cell).startswith("CVE-")), None)
                cve_col_idx = 0 if sample_cve else 2
            
            cves = collect_cves_from_file(file_path, cve_col_idx)
            file_cves[file_path] = cves
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            continue

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    all_rows = []
    headers = []
    for file_path in files:
        try:
            wb = openpyxl.load_workbook(file_path)
            ws = wb.active
            headers.append(next(ws.iter_rows(values_only=True)))  # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ —Å CVE –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
            first_row = headers[-1]
            if "–ù–æ–º–µ—Ä CVE" in first_row or "CVE_ID" in first_row:
                cve_col_idx = first_row.index("–ù–æ–º–µ—Ä CVE") if "–ù–æ–º–µ—Ä CVE" in first_row else first_row.index("CVE_ID")
            else:
                sample_cve = next((str(cell).strip() for cell in first_row if str(cell).startswith("CVE-")), None)
                cve_col_idx = 0 if sample_cve else 2
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ —Å –ø–∞–∫–µ—Ç–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å)
            pkg_col_idx = None
            if "–ü–∞–∫–µ—Ç" in first_row:
                pkg_col_idx = first_row.index("–ü–∞–∫–µ—Ç")
            elif len(first_row) > 2:  # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –ø–∞–∫–µ—Ç –≤ 3-–π –∫–æ–ª–æ–Ω–∫–µ
                pkg_col_idx = 2
            
            for row in ws.iter_rows(values_only=True, min_row=2):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                all_rows.append((row[cve_col_idx], row, pkg_col_idx))
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—Ç—Ä–æ–∫ –∏–∑ {file_path}: {e}")
            continue

    # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    unique_rows = {}
    for cve, row, pkg_col_idx in all_rows:
        cve = str(cve).strip() if cve else ""
        if cve and cve not in unique_rows:
            unique_rows[cve] = (row, pkg_col_idx)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–∫—Ä—ã—Ç—ã—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
    closed_rows = []
    if closed_file and os.path.isfile(closed_file):
        closed_cves = set()
        wb_closed = openpyxl.load_workbook(closed_file)
        for row in wb_closed.active.iter_rows(values_only=True, min_row=2):
            if row[1]:  # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ CVE –≤–æ –≤—Ç–æ—Ä–æ–π –∫–æ–ª–æ–Ω–∫–µ
                closed_cves.add(str(row[1]).strip())
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Ç–∫—Ä—ã—Ç—ã–µ –∏ –∑–∞–∫—Ä—ã—Ç—ã–µ
        open_rows = {}
        for cve, (row, pkg_col_idx) in unique_rows.items():
            if cve in closed_cves:
                closed_rows.append((row, pkg_col_idx))
            else:
                open_rows[cve] = (row, pkg_col_idx)
        unique_rows = open_rows

    # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∫–Ω–∏–≥—É
    wb_out = openpyxl.Workbook()
    ws_out = wb_out.active
    ws_out.title = "–û—Ç–∫—Ä—ã—Ç—ã–µ CVE"
    
    # –°–æ–∑–¥–∞–µ–º –ª–∏—Å—Ç –¥–ª—è –∑–∞–∫—Ä—ã—Ç—ã—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if closed_rows:
        ws_closed = wb_out.create_sheet("–ó–∞–∫—Ä—ã—Ç—ã–µ CVE")
    
    # –°–æ–∑–¥–∞–µ–º –ª–∏—Å—Ç –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–∞–∫–µ—Ç–æ–≤
    ws_missing = wb_out.create_sheet("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–∞–∫–µ—Ç—ã")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    if headers:
        base_header = list(headers[0])
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        seen = set()
        base_header = [x for x in base_header if not (x in seen or seen.add(x))]
    else:
        base_header = ["–ù–æ–º–µ—Ä CVE", "–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã", "–ü–∞–∫–µ—Ç", "–û–ø–∏—Å–∞–Ω–∏–µ", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏", "–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏"]
    
    extended_header = base_header + ["–§–°–¢–≠–ö", "–ê—Å—Ç—Ä–∞", "OVAL"]
    ws_out.append(extended_header)
    if closed_rows:
        ws_closed.append(extended_header)
    ws_missing.append(extended_header)
    
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–∫–µ—Ç–∞
    def is_package_missing(row, pkg_col_idx):
        if not packages or pkg_col_idx is None or len(row) <= pkg_col_idx:
            return False
        pkg_name = str(row[pkg_col_idx]).strip().lower()
        return pkg_name and pkg_name not in packages

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    for cve, (row, pkg_col_idx) in unique_rows.items():
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–∫–µ—Ç–∞
        if is_package_missing(row, pkg_col_idx):
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ –ª–∏—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–∞–∫–µ—Ç–æ–≤
            marks = []
            for file_path in files:
                marks.append("+" if cve in file_cves.get(file_path, set()) else "")
            
            if len(files) == 1:
                marks = marks * 3
            elif len(files) == 2:
                marks = marks + [""]
            
            extended_row = list(row) + marks[:3]
            ws_missing.append(extended_row)
            continue
            
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
        marks = []
        for file_path in files:
            marks.append("+" if cve in file_cves.get(file_path, set()) else "")
        
        if len(files) == 1:
            marks = marks * 3
        elif len(files) == 2:
            marks = marks + [""]
        
        extended_row = list(row) + marks[:3]
        ws_out.append(extended_row)
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –∑–∞–∫—Ä—ã—Ç—ã–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
    if closed_rows:
        for row, pkg_col_idx in closed_rows:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–∫–µ—Ç–∞
            if is_package_missing(row, pkg_col_idx):
                marks = []
                for file_path in files:
                    marks.append("+" if str(row[0]).strip() in file_cves.get(file_path, set()) else "")
                
                if len(files) == 1:
                    marks = marks * 3
                elif len(files) == 2:
                    marks = marks + [""]
                
                extended_row = list(row) + marks[:3]
                ws_missing.append(extended_row)
                continue
                
            cve = str(row[0]).strip() if row[0] else ""
            marks = []
            for file_path in files:
                marks.append("+" if cve in file_cves.get(file_path, set()) else "")
            
            if len(files) == 1:
                marks = marks * 3
            elif len(files) == 2:
                marks = marks + [""]
            
            extended_row = list(row) + marks[:3]
            ws_closed.append(extended_row)
    
    wb_out.save(output_file)
    return len(all_rows) - len(unique_rows), len(closed_rows)

def load_update_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
    return {}

def save_update_cache(cache):
    try:
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

def extract_update_number_from_url(url):
    with cache_lock:  # üîê –ë–ª–æ–∫–∏—Ä—É–µ–º —á—Ç–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
        cache = load_update_cache()

    if url in cache:
        return cache[url]

    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        resp = requests.get(url, timeout=7, headers=headers)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            title = soup.find("title")
            if title:
                match = re.search(
                    r'–æ–ø–µ—Ä–∞—Ç–∏–≤[^\d]*–æ–±–Ω–æ–≤–ª–µ–Ω[^\d]*‚Ññ?\s*([A-Z–ê-–Ø\d\-.]+)',
                    title.text,
                    re.IGNORECASE
                )
                if match:
                    number = f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ {match.group(1)}"

                    # üîÑ –ü–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º –∫—ç—à –ø–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ç–µ—Ä–µ—Ç—å —á—É–∂–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                    with cache_lock:
                        updated_cache = load_update_cache()
                        updated_cache[url] = number
                        save_update_cache(updated_cache)

                    return number
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")

    return url  # –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∏–ª–∏ –æ—à–∏–±–∫–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—É—Ç—å —Å—Å—ã–ª–∫—É

#------ –ü–µ—Ä–µ–≤–æ–¥

def extract_text_from_link_and_translate(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, timeout=10, headers=headers)
        if resp.status_code == 200:
            lines = resp.text.splitlines()
            if len(lines) >= 241:
                raw_line = lines[240]  # —Å—Ç—Ä–æ–∫–∞ ‚Ññ241 (–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å 0)
                soup = BeautifulSoup(raw_line, 'html.parser')
                cleaned = soup.get_text(strip=True)
                translated = GoogleTranslator(source='auto', target='ru').translate(cleaned)
                return translated
    except Exception:
        pass
    return "‚Äî"

import os
import re
import tempfile
import threading
import requests
import openpyxl
import pandas as pd
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed

from tkinterdnd2 import TkinterDnD, DND_FILES
import tkinter as tk
from tkinter import StringVar, filedialog
from ttkbootstrap import Style
from ttkbootstrap.widgets import Button, Label, Frame, Progressbar, Combobox


# --- –ö–ª–∞—Å—Å GUI ---
class FileEntry:
    def __init__(self, master, file_path, scan_type, on_change):
        self.frame = Frame(master)
        self.frame.pack(fill="x", pady=2)
        Label(self.frame, text=os.path.basename(file_path), width=40).pack(side="left", padx=5)
        self.var = StringVar(value=scan_type)
        self.combo = Combobox(self.frame, textvariable=self.var, values=["oval", "astra", "fstec"], width=10, state="readonly")
        self.combo.pack(side="left", padx=5)
        self.combo.bind("<<ComboboxSelected>>", lambda e: on_change())
        self.path = file_path
    def get_selected_type(self): return self.var.get()
    def get_path(self): return self.path

class VulnParserApp:
    def __init__(self, root):
        self.save_path_var = StringVar()
        self.root = root
        root.title("‚õ© PARSERLOX ‚õ©")
        self.style = Style("darkly")
        self.file_entries, self.temp_files = [], []
        reset_frame = Frame(root)
        reset_frame.pack(anchor="nw", padx=10, pady=10)
        self.reset_btn = Button(reset_frame, text="üîÑ", bootstyle="danger", 
                              command=self.reset_all, width=3)
        self.reset_btn.pack(side="left", padx=5)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–æ–≤
        self.select_files_btn = Button(reset_frame, text="üìÅ –í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª—ã", 
                                      bootstyle="info", 
                                      command=self.select_html_files)
        self.select_files_btn.pack(side="left", padx=5)
        
        self.drop_label = Label(root, text="–ü–µ—Ä–µ—Ç–∞—â–∏ —Å—é–¥–∞ —Ñ–∞–π–ª—ã (–¥–æ 3-—Ö) !!! –î–õ–Ø HYPRLAND env GDK_BACKEND=x11 <comand>", bootstyle="info")
        self.drop_label.pack(pady=0, ipadx=0, ipady=70, fill="both")
        self.drop_label.drop_target_register(DND_FILES)
        self.drop_label.dnd_bind('Drop', self.handle_drop)
        
        self.files_frame = Frame(root)
        self.files_frame.pack(pady=5, fill="x")
        self.closed_path_var, self.desc_path_var = StringVar(), StringVar()
        self._make_file_selector("–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Excel-—Ñ–∞–π–ª–∞:", self.save_path_var, self.select_save_path)

        self._make_file_selector("–§–∞–π–ª —Å –∑–∞–∫—Ä—ã—Ç—ã–º–∏ —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏: (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", self.closed_path_var, self.select_closed_file)
        self._make_file_selector("–§–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", self.desc_path_var, self.select_desc_file)


        self.packages_path_var = StringVar()
        self._make_file_selector("–§–∞–π–ª —Å –ø–∞–∫–µ—Ç–∞–º–∏ (–∏–º—è;–≤–µ—Ä—Å–∏—è):", self.packages_path_var, self.select_packages_file)

        self.start_btn = Button(root, text="üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", bootstyle="success", command=self.start_parsing)
        self.start_btn.pack(pady=10)
        self.report_btn = Button(root, text="üì§ –í—ã–≥—Ä—É–∑–∏—Ç—å –æ—Ç—á—ë—Ç", bootstyle="warning", command=self.export_report)
        self.report_btn.pack(pady=5)
        self.report_btn.config(state="disabled")  # –°–Ω–∞—á–∞–ª–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞

        self.progress = Progressbar(root, maximum=100)
        self.progress.pack(fill="x", padx=10)
        self.log_text = tk.Text(root, height=10, state='disabled', bg='#1e1e1e', fg="#d4d4d4", wrap='word')
        self.log_text.pack(fill='both', padx=10, pady=(5,10), expand=True)
        self.log_scroll = tk.Scrollbar(root, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=self.log_scroll.set)
        self.log_scroll.pack(side="right", fill="y")
        self.report_mode = tk.BooleanVar(value=False)
        self.mode_var = StringVar(value="–ü–∞—Ä—Å–µ—Ä HTML")
        mode_frame = Frame(root)
        mode_frame.pack(pady=5)
        Label(mode_frame, text="–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:", bootstyle="info").pack(side="left", padx=5)
        self.mode_combo = Combobox(mode_frame, textvariable=self.mode_var, 
                                 values=["–ü–∞—Ä—Å–µ—Ä HTML", "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å .xlsx", "–ü–æ–∏—Å–∫ CVE –Ω–∞ GitHub", "–ü–æ–∏—Å–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –≤ –ø–∞–∫–µ—Ç–∞—Ö"], 
                                 state="readonly")
        self.mode_combo.pack(side="left")
        self.cve_offline_btn = Button(self.root, text="üîé –ü–æ–∏—Å–∫ CVE –ø–æ CPE (dpkg) –æ—Ñ–ª–∞–π–Ω", bootstyle="info", command=self.start_cve_offline_search)
        self.cve_offline_btn.pack(pady=5)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è GitHub Token
        self.github_token_var = StringVar()
        self._make_github_token_field()
        self.load_config()

    def select_html_files(self):
        """–†—É—á–Ω–æ–π –≤—ã–±–æ—Ä HTML-—Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –¥–∏–∞–ª–æ–≥–æ–≤–æ–µ –æ–∫–Ω–æ"""
        if len(self.file_entries) >= 3:
            self.log("‚ö†Ô∏è –ú–∞–∫—Å–∏–º—É–º 3 HTML-—Ñ–∞–π–ª–∞")
            return
            
        files = filedialog.askopenfilenames(
            title="–í—ã–±–µ—Ä–∏—Ç–µ HTML —Ñ–∞–π–ª—ã",
            filetypes=[("HTML files", "*.html *.htm"), ("All files", "*.*")]
        )
        
        if not files:
            return
            
        for path in files:
            if len(self.file_entries) >= 3:
                self.log("‚ö†Ô∏è –ú–∞–∫—Å–∏–º—É–º 3 HTML-—Ñ–∞–π–ª–∞")
                break
                
            fname = os.path.basename(path).lower()
            if fname.endswith(".html") or fname.endswith(".htm"):
                scan_type = self.detect_type(path)
                entry = FileEntry(self.files_frame, path, scan_type, self.refresh)
                self.file_entries.append(entry)
                self.log(f"üì• –î–æ–±–∞–≤–ª–µ–Ω HTML-—Ñ–∞–π–ª: {fname}")
            else:
                self.log(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è HTML: {fname}")
        
        self.refresh()

    def select_packages_file(self):
        path = filedialog.askopenfilename(filetypes=[("Text files", "*.txt"), ("All files", "*.*")])
        if path:
            self.packages_path_var.set(path)
            self.log(f"üì¶ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª —Å –ø–∞–∫–µ—Ç–∞–º–∏: {os.path.basename(path)}")

    def _make_file_selector(self, label_text, var, command):
        frame = Frame(self.root)
        frame.pack(pady=5, fill="x")
        Label(frame, text=label_text, bootstyle="info").pack(side="left", padx=5)
        Label(frame, textvariable=var, width=50, anchor="w", relief="sunken").pack(side="left", padx=5)
        Button(frame, text="–í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª", bootstyle="secondary", command=command).pack(side="left", padx=5)

    def log(self, msg):
        self.log_text.config(state='normal')
        self.log_text.insert('end', msg + "\n")
        self.log_text.see('end')
        self.log_text.config(state='disabled')
        self.root.update_idletasks()

    def handle_drop(self, event):
        paths = self.root.tk.splitlist(event.data)
        for path in paths:
            fname = os.path.basename(path).lower()
            if fname.endswith(".html") or fname.endswith(".htm"):
                if len(self.file_entries) >= 3:
                    self.log("‚ö†Ô∏è –ú–∞–∫—Å–∏–º—É–º 3 HTML-—Ñ–∞–π–ª–∞")
                    continue
                scan_type = self.detect_type(path)
                entry = FileEntry(self.files_frame, path, scan_type, self.refresh)
                self.file_entries.append(entry)
                self.log(f"üì• –î–æ–±–∞–≤–ª–µ–Ω HTML-—Ñ–∞–π–ª: {fname}")
            elif any(x in fname for x in ["–∑–∞–∫—Ä—ã—Ç", "closed", "fix"]):
                self.closed_path_var.set(path)
                self.log(f"üì• –§–∞–π–ª –∑–∞–∫—Ä—ã—Ç—ã—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {fname}")
            elif any(x in fname for x in ["–æ–ø–∏—Å–∞–Ω", "desc", "vullist"]):
                self.desc_path_var.set(path)
                self.log(f"üì• –§–∞–π–ª –æ–ø–∏—Å–∞–Ω–∏–π —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {fname}")
            else:
                self.log(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª: {fname}")
        self.refresh()

    def detect_type(self, path):
        name = os.path.basename(path).lower()
        if "fstec" in name: return "fstec"
        elif "astra" in name: return "astra"
        return "oval"

    def refresh(self):
        self.progress['value'] = 0

    def select_closed_file(self):
        path = filedialog.askopenfilename(filetypes=[("Excel —Ñ–∞–π–ª—ã", "*.xlsx"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")])
        if path:
            self.closed_path_var.set(path)
            self.log(f"üìÇ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –∑–∞–∫—Ä—ã—Ç—ã—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {os.path.basename(path)}")

    def select_desc_file(self):
        path = filedialog.askopenfilename(filetypes=[("Excel —Ñ–∞–π–ª—ã", "*.xlsx"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")])
        if path:
            self.desc_path_var.set(path)
            self.log(f"üìÇ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –æ–ø–∏—Å–∞–Ω–∏–π: {os.path.basename(path)}")

    def _make_github_token_field(self):
        frame = Frame(self.root)
        frame.pack(pady=5, fill="x")
        Label(frame, text="GitHub Token:", bootstyle="info").pack(side="left", padx=5)
        entry = tk.Entry(frame, textvariable=self.github_token_var, width=50, show="*")
        entry.pack(side="left", padx=5)
        Button(frame, text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å", bootstyle="secondary", 
              command=self.save_github_token).pack(side="left", padx=5)
    
    def save_github_token(self):
        global GITHUB_TOKEN, HEADERS
        token = self.github_token_var.get().strip()
        if token:
            GITHUB_TOKEN = token
            HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}
            self.log("‚úÖ GitHub Token —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            self.save_config()
            
    def load_config(self):
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.save_path_var.set(data.get("save_path", ""))
                    self.github_token_var.set(data.get("github_token", ""))
                    if self.github_token_var.get():
                        self.save_github_token()  # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            except Exception as e:
                self.log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å config.json: {e}")
    
    def save_config(self):
        try:
            with open(CONFIG_FILE, "w", encoding="utf-8") as f:
                json.dump({
                    "save_path": self.save_path_var.get(),
                    "github_token": self.github_token_var.get()
                }, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å config.json: {e}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ CVE
    def github_repo_search_count(self, query):
        """–í–µ—Ä–Ω—É—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        try:
            response = requests.get(SEARCH_URL, headers=HEADERS, params={"q": query})
            response.raise_for_status()
            return response.json().get("total_count", 0)
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ '{query}': {e}")
            return 0
    
    def process_cve(self, cve):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω CVE: –Ω–∞–π—Ç–∏ total_count –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        query = f"{cve}"
        total = self.github_repo_search_count(query)
        self.log(f"{cve}: {total} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        if total > 1:
            return cve, total
        return None
    
    def search_cve_on_github(self):
        file_path = filedialog.askopenfilename(
            filetypes=[("Excel files", "*.xlsx"), ("All files", "*.*")],
            title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å CVE"
        )
        if not file_path:
            return
            
        output_path = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt"), ("All files", "*.*")],
            title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞"
        )
        if not output_path:
            return
            
        try:
            df = pd.read_excel(file_path)
            cve_list = df.iloc[:, 0].dropna().astype(str).tolist()
            found = {}
            
            self.log(f"üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ {len(cve_list)} CVE –Ω–∞ GitHub...")
            self.progress['value'] = 0
            step = 100 / len(cve_list)
            
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = [executor.submit(self.process_cve, cve) for cve in cve_list]
                
                for future in as_completed(futures):
                    result = future.result()
                    if result:
                        cve, total = result
                        found[cve] = total
                    self.progress['value'] += step
                    self.root.update()
            
            with open(output_path, "w") as f:
                for cve, total in found.items():
                    f.write(f"{cve}: {total} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n")
            
            self.log(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ù–∞–π–¥–µ–Ω–æ {len(found)} CVE. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_path}")
            self.progress['value'] = 100
            
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            self.progress['value'] = 0
    
    def start_parsing(self):
        selected_mode = self.mode_var.get()
        if selected_mode == "–ü–∞—Ä—Å–µ—Ä HTML":
            threading.Thread(target=self._run, daemon=True).start()
        elif selected_mode == "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å .xlsx":
            threading.Thread(target=self.merge_xlsx_folder, daemon=True).start()
        elif selected_mode == "–ü–æ–∏—Å–∫ CVE –Ω–∞ GitHub":
            threading.Thread(target=self.search_cve_on_github, daemon=True).start()
        elif selected_mode == "–ü–æ–∏—Å–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –≤ –ø–∞–∫–µ—Ç–∞—Ö":
            threading.Thread(target=self.search_vuln_by_packages, daemon=True).start()


    def _run(self):
        if not self.file_entries:
            self.log("‚ùå –ù–µ—Ç HTML-—Ñ–∞–π–ª–æ–≤")
            return

        self.progress['value'] = 0
        self.temp_files.clear()
        step = 100 / len(self.file_entries)

        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            for entry in self.file_entries:
                scan_type, path = entry.get_selected_type(), entry.get_path()
                func = {"oval": parse_html_oval, "astra": parse_html_astra, "fstec": parse_html_fstec}.get(scan_type)
                if not func:
                    self.log(f"‚ùå –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –¥–ª—è {scan_type}")
                    return
                self.log(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(path)} –∫–∞–∫ {scan_type}...")
                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx")
                tmp.close()
                self.temp_files.append(tmp.name)
                try:
                    func(path, tmp.name)
                    self.log(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω {os.path.basename(path)}")
                except Exception as e:
                    self.log(f"‚ùå –û—à–∏–±–∫–∞ –≤ {path}: {e}")
                    return
                self.progress['value'] += step


        self.log("üîÄ –û–±—ä–µ–¥–∏–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        out_file = self.save_path_var.get().strip() or os.path.join(os.path.expanduser("~"), "merged_cves.xlsx")
        dup, closed = merge_cve_rows(
        out_file,
        self.closed_path_var.get() or None,
        self.packages_path_var.get() or None,
        *self.temp_files  # –ø–µ—Ä–µ–¥–∞—ë–º —Å—Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å (1‚Äì3)
        )   
        self.log(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {dup}, –∑–∞–∫—Ä—ã—Ç—ã—Ö: {closed}")
        self.progress['value'] = 80

        desc_file = self.desc_path_var.get() or None
        if desc_file and os.path.isfile(desc_file):
            self.log("üîó –î–æ–±–∞–≤–ª—è—é –Ω–æ–º–µ—Ä–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∏–∑ wiki-—Å—Å—ã–ª–æ–∫...")
            try:
                self.add_links_to_merged(out_file, desc_file)
                self.progress['value'] = 100
            except Exception as e:
                self.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Å—ã–ª–æ–∫: {e}")
                self.progress['value'] = 100
        else:
            self.progress['value'] = 100
            self.log(f"üìÑ –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {out_file}")
        self.report_btn.config(state="normal")
        self.last_out_file = out_file
    def export_report(self):
        path = self.last_out_file.replace(".xlsx", "_FULL.xlsx")

        if not os.path.isfile(path):
            self.log("‚ö†Ô∏è –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return

        try:
            self.log("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª —Å —É—è–∑–≤–∏–º–æ—Å—Ç—è–º–∏...")
            df = pd.read_excel(path)
            self.log(f"üìä –°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {df.columns.tolist()}")
            self.log(f"üìà –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(df)}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –≤–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –∏ –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã
            comp_win = tk.Toplevel(self.root)
            comp_win.title("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç—á—ë—Ç–∞")
            comp_win.geometry("400x350")
            
            # –ü–æ–ª–µ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
            Label(comp_win, text="–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞:", bootstyle="info").pack(pady=5)
            comp_var = StringVar()
            comp_entry = tk.Entry(comp_win, textvariable=comp_var, width=40)
            comp_entry.pack(pady=5)
            
            # –ü–æ–ª–µ –¥–ª—è –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã
            Label(comp_win, text="–í–≤–µ–¥–∏—Ç–µ –≤–µ—Ä—Å–∏—é —Å–∏—Å—Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä 1.7, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", bootstyle="info").pack(pady=5)
            version_var = StringVar()
            version_entry = tk.Entry(comp_win, textvariable=version_var, width=40)
            version_entry.pack(pady=5)
            
            # –ß–µ–∫–±–æ–∫—Å –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤–µ—Ä—Å–∏–∏
            filter_var = tk.BooleanVar(value=False)
            filter_check = Checkbutton(comp_win, text="–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã", variable=filter_var, bootstyle="info")
            filter_check.pack(pady=5)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —á–µ–∫–±–æ–∫—Å—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ CVSS
            Label(comp_win, text="–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ CVSS 3.0:", bootstyle="info").pack(pady=(10,5))
            
            # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —á–µ–∫–±–æ–∫—Å–æ–≤ CVSS
            remove_avn_var = tk.BooleanVar(value=False)
            remove_uir_var = tk.BooleanVar(value=False)
            remove_prn_var = tk.BooleanVar(value=False)
            
            # –ß–µ–∫–±–æ–∫—Å—ã CVSS
            Checkbutton(comp_win, text="–£–¥–∞–ª–∏—Ç—å AV:N", variable=remove_avn_var, 
                    bootstyle="info").pack(anchor="w", padx=20)
            Checkbutton(comp_win, text="–£–¥–∞–ª–∏—Ç—å UI:R", variable=remove_uir_var, 
                    bootstyle="info").pack(anchor="w", padx=20)
            Checkbutton(comp_win, text="–£–¥–∞–ª–∏—Ç—å PR:N", variable=remove_prn_var, 
                    bootstyle="info").pack(anchor="w", padx=20)
            
            comp_entry.focus()
            done = threading.Event()

            def submit_component():
                done.set()
                comp_win.destroy()

            Button(comp_win, text="OK", command=submit_component, bootstyle="success").pack(pady=10)
            comp_win.grab_set()
            self.root.wait_window(comp_win)

            done.wait()
            component_name = comp_var.get().strip()
            system_version = version_var.get().strip()
            filter_by_version = filter_var.get()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            self.log(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
            self.log(f"   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç: {component_name}")
            self.log(f"   –í–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã: {system_version}")
            self.log(f"   –§–∏–ª—å—Ç—Ä –ø–æ –≤–µ—Ä—Å–∏–∏: {filter_by_version}")
            self.log(f"   –£–¥–∞–ª–∏—Ç—å AV:N: {remove_avn_var.get()}")
            self.log(f"   –£–¥–∞–ª–∏—Ç—å UI:R: {remove_uir_var.get()}")
            self.log(f"   –£–¥–∞–ª–∏—Ç—å PR:N: {remove_prn_var.get()}")
            
            if not component_name:
                self.log("‚ö†Ô∏è –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ –≤–≤–µ–¥—ë–Ω. –û—Ç–º–µ–Ω–∞.")
                return
                
            if filter_by_version and not system_version:
                self.log("‚ö†Ô∏è –í—ã–±—Ä–∞–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤–µ—Ä—Å–∏–∏, –Ω–æ –≤–µ—Ä—Å–∏—è –Ω–µ –≤–≤–µ–¥–µ–Ω–∞. –û—Ç–º–µ–Ω–∞.")
                return

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é CVSS –µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–æ–ª–±–µ—Ü —Å –≤–µ–∫—Ç–æ—Ä–æ–º
            if "CVSS 3.0" in df.columns:
                self.log("üîç –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ CVSS 3.0...")
                original_count = len(df)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–æ–ª–±—Ü–µ
                cvss_non_null = df["CVSS 3.0"].notna().sum()
                self.log(f"   –ù–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π CVSS 3.0: {cvss_non_null}/{original_count}")
                
                if cvss_non_null > 0:
                    # –í—ã–≤–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    sample_values = df["CVSS 3.0"].dropna().head(3).tolist()
                    self.log(f"   –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π CVSS: {sample_values}")
                
                # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                mask = pd.Series([True] * len(df), index=df.index)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —á–µ–∫–±–æ–∫—Å –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –º–∞—Å–∫—É
                if remove_avn_var.get():
                    avn_count_before = len(df[df["CVSS 3.0"].str.contains(r'\bAV:N\b', na=False, regex=True)])
                    mask &= ~df["CVSS 3.0"].str.contains(r'\bAV:N\b', na=False, regex=True)
                    avn_count_after = len(df[~mask])
                    self.log(f"   AV:N: –Ω–∞–π–¥–µ–Ω–æ {avn_count_before}, –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {avn_count_after}")
                
                if remove_uir_var.get():
                    uir_count_before = len(df[df["CVSS 3.0"].str.contains(r'\bUI:R\b', na=False, regex=True)])
                    mask &= ~df["CVSS 3.0"].str.contains(r'\bUI:R\b', na=False, regex=True)
                    uir_count_after = len(df[~mask])
                    self.log(f"   UI:R: –Ω–∞–π–¥–µ–Ω–æ {uir_count_before}, –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {uir_count_after}")
                
                if remove_prn_var.get():
                    prn_count_before = len(df[df["CVSS 3.0"].str.contains(r'\bPR:N\b', na=False, regex=True)])
                    mask &= ~df["CVSS 3.0"].str.contains(r'\bPR:N\b', na=False, regex=True)
                    prn_count_after = len(df[~mask])
                    self.log(f"   PR:N: –Ω–∞–π–¥–µ–Ω–æ {prn_count_before}, –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ {prn_count_after}")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
                df_filtered = df[mask]
                removed_count = original_count - len(df_filtered)
                
                self.log(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: —É–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç—Ä–æ–∫")
                self.log(f"   –û—Å—Ç–∞–ª–æ—Å—å —Å—Ç—Ä–æ–∫: {len(df_filtered)}")
                
                if removed_count > 0:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã
                    removed_rows = df[~mask]
                    if not removed_rows.empty:
                        self.log("   –£–¥–∞–ª–µ–Ω–Ω—ã–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏:")
                        for idx, row in removed_rows.head(5).iterrows():
                            cve = row.get("–ù–æ–º–µ—Ä CVE", row.get("CVE_ID", "N/A"))
                            cvss = row.get("CVSS 3.0", "N/A")
                            self.log(f"     - {cve}: {cvss}")
                        if len(removed_rows) > 5:
                            self.log(f"     ... –∏ –µ—â–µ {len(removed_rows) - 5}")
                
                df = df_filtered
            else:
                self.log("‚ÑπÔ∏è –°—Ç–æ–ª–±–µ—Ü 'CVSS 3.0' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã
            if filter_by_version and "–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ" in df.columns:
                self.log("üîç –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã...")
                def filter_updates(update_text):
                    if not isinstance(update_text, str):
                        return False
                    
                    if "–û–±–Ω–æ–≤–∏—Ç—å –û–° –¥–æ –≤–µ—Ä—Å–∏–∏" in update_text:
                        return True
                    
                    version_pattern = re.compile(r'–æ–ø–µ—Ä–∞—Ç–∏–≤[^\d]*–æ–±–Ω–æ–≤–ª–µ–Ω[^\d]*‚Ññ?\s*([\d.]+)', re.IGNORECASE)
                    match = version_pattern.search(update_text)
                    if match:
                        update_version = match.group(1)
                        return update_version.startswith(system_version + '.') or update_version == system_version
                    return False
                    
                df = df[df["–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"].apply(filter_updates) | 
                    (df["–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"].isna())]
                
                self.log(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤–µ—Ä—Å–∏–∏: {len(df)} —Å—Ç—Ä–æ–∫")

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
            self.log("üìã –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ—Ç—á–µ—Ç–∞...")
            if "–û–ø–∏—Å–∞–Ω–∏–µ" in df.columns and "–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (BDU)" in df.columns:
                df["–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (BDU)"] = df["–û–ø–∏—Å–∞–Ω–∏–µ"]
                self.log("   –°–∫–æ–ø–∏—Ä–æ–≤–∞–ª–∏ –û–ø–∏—Å–∞–Ω–∏–µ –≤ –°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã")

            if "–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏" in df.columns:
                df.rename(columns={"–£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏": "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å"}, inplace=True)
                self.log("   –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–ª–∏ –£—Ä–æ–≤–µ–Ω—å –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –≤ –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å")

            if "–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ" in df.columns:
                df.rename(columns={"–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é"}, inplace=True)
                self.log("   –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–ª–∏ –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")

            rename_map = {
                "–ù–æ–º–µ—Ä CVE": "–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É—è–∑–≤–∏–º–æ—Å—Ç–∏",
                "–°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (BDU)": "–û–ø–∏—Å–∞–Ω–∏–µ",
                "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å": "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å",
                "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—Å—Å—ã–ª–∫–∏)": "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç"
            }
            
            selected_cols = [col for col in rename_map if col in df.columns]
            self.log(f"   –í—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {selected_cols}")
            
            df = df[selected_cols + (["–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é"] if "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é" in df.columns else [])]
            df.rename(columns=rename_map, inplace=True)

            if "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç" in df.columns and len(df) > 1:
                df.loc[0:, "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç"] = component_name
                self.log(f"   –ó–∞–ø–æ–ª–Ω–∏–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º '{component_name}'")

            if len(df.columns) >= 3:
                report_path = path.replace("_FULL.xlsx", " - –ö –û–¢–ß–ï–¢–£.xlsx")
                df.to_excel(report_path, index=False)
                self.log(f"‚úÖ –û—Ç—á—ë—Ç–Ω—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {report_path}")
                self.log(f"üìä –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(df)}")
            else:
                self.log(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ—Ç—á—ë—Ç–∞. –ü–æ–ª—É—á–µ–Ω–æ: {df.columns.tolist()}")

        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ç—á—ë—Ç–∞: {e}")
            import traceback
            self.log(f"‚ùå –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")




    def add_links_to_merged(self, merged_path, desc_path):
        df_merged = pd.read_excel(merged_path)
        column3 = df_merged.iloc[:, 2]
        self.log("üåê –ü–µ—Ä–µ–≤–æ–∂—É –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑ —Å—Å—ã–ª–æ–∫ –≤ 3 —Å—Ç–æ–ª–±—Ü–µ...")

        def process_desc_link(index_val):
            i, val = index_val
            if isinstance(val, str) and val.startswith("http"):
                self.log(f"üîé {i+1}: –ü–∞—Ä—Å–∏–Ω–≥ {val}")
                return i, extract_text_from_link_and_translate(val)
            else:
                return i, val

        translated_descriptions = [None] * len(column3)
        with ThreadPoolExecutor(max_workers=20) as executor:
            for i, result in executor.map(process_desc_link, enumerate(column3)):
                translated_descriptions[i] = result

        df_merged.iloc[:, 2] = translated_descriptions

        
        df_desc = pd.read_excel(desc_path)

        file1_vals = df_merged.iloc[:, 1]  # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç—É—Ç BDU –∏–ª–∏ CVE ID
        file2_keys = df_desc.iloc[:, 0]    # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç—É—Ç –∫–ª—é—á–∏
        file2_targets = df_desc.iloc[:, 13]  # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç—É—Ç —Å—Å—ã–ª–∫–∏

        value_to_link = dict(zip(file2_keys, file2_targets))

        urls = []
        for val in file1_vals:
            raw_link = value_to_link.get(val, "")
            match = re.search(r'(https?://wiki\.astralinux[^\s"]+)', str(raw_link))
            url = match.group(1) if match else ""
            urls.append(url)

        found_urls = [url for url in urls if url]
        self.log(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ wiki.astra: {len(found_urls)}")

        results = ["‚Äî"] * len(urls)

        with ThreadPoolExecutor(max_workers=30) as executor:
            futures = {executor.submit(extract_update_number_from_url, url): i for i, url in enumerate(urls) if url}
            for future in as_completed(futures):
                i = futures[future]
                url = urls[i]
                self.log(f"üåê –ü–∞—Ä—Å–∏–º: {url}")
                try:
                    results[i] = future.result()
                except Exception as e:
                    self.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
                    results[i] = "‚Äî"

        df_merged['–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ'] = [r if isinstance(r, str) else str(r) for r in results]
        out_path = merged_path.replace(".xlsx", "_FULL.xlsx")
        df_merged.to_excel(out_path, index=False)
        self.log(f"üìÑ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")
    
    def select_save_path(self):
        path = filedialog.asksaveasfilename(
            defaultextension=".xlsx",
            filetypes=[("Excel —Ñ–∞–π–ª—ã", "*.xlsx"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")],
            title="–í—ã–±–µ—Ä–∏—Ç–µ –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
        )
        if path:
            self.save_path_var.set(path)
            self.log(f"üíæ –§–∞–π–ª –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫: {os.path.basename(path)}")
        self.save_config()


    

    def merge_xlsx_folder(self):
        folder = filedialog.askdirectory(title="–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞–ø–∫—É —Å .xlsx —Ñ–∞–π–ª–∞–º–∏")
        if not folder:
            self.log("‚ö†Ô∏è –ü–∞–ø–∫–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞.")
            return

        self.log(f"üìÅ –û–±—ä–µ–¥–∏–Ω—è—é .xlsx –∏–∑ –ø–∞–ø–∫–∏: {folder}")
        try:
            all_data = []  # –ë—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            file_paths = []  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            
            # –ß–∏—Ç–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
            for filename in os.listdir(folder):
                if filename.endswith(".xlsx"):
                    path = os.path.join(folder, filename)
                    self.log(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {filename}")
                    
                    try:
                        df = pd.read_excel(path)
                        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –∏–º–µ–Ω–µ–º —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                        df['source_file'] = filename
                        all_data.append(df)
                        file_paths.append(path)
                    except Exception as e:
                        self.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filename}: {e}")
                        continue
            
            if not all_data:
                self.log("‚ùå –ù–µ—Ç .xlsx —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ.")
                return
            
            self.log(f"‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_data)}")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            merged_df = pd.concat(all_data, ignore_index=True)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            self.log(f"üìä –°—Ç–æ–ª–±—Ü—ã –≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ: {list(merged_df.columns)}")
            self.log(f"üìà –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(merged_df)}")
            
            if len(merged_df.columns) < 4:
                self.log("‚ùå –§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 4 —Å—Ç–æ–ª–±—Ü–∞")
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
            first_col_name = merged_df.columns[0]
            fourth_col_name = merged_df.columns[3] if len(merged_df.columns) > 3 else "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç"
            
            self.log(f"üîç –ü–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü: '{first_col_name}', –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å—Ç–æ–ª–±–µ—Ü: '{fourth_col_name}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –ø–µ—Ä–≤–æ–º—É —Å—Ç–æ–ª–±—Ü—É
            duplicates = merged_df.duplicated(subset=[first_col_name], keep=False)
            duplicate_count = duplicates.sum()
            
            if duplicate_count > 0:
                self.log(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –ø–µ—Ä–≤–æ–º—É —Å—Ç–æ–ª–±—Ü—É: {duplicate_count}")
                
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                result_rows = {}
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
                for idx, row in merged_df.iterrows():
                    key = str(row[first_col_name]).strip() if pd.notna(row[first_col_name]) else f"empty_{idx}"
                    
                    if key not in result_rows:
                        # –ü–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É
                        result_rows[key] = {
                            'row': row.tolist(),
                            'components': {str(row[fourth_col_name]).strip()} if pd.notna(row[fourth_col_name]) else set(),
                            'files': {row['source_file']}
                        }
                    else:
                        # –î—É–±–ª–∏–∫–∞—Ç - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                        if pd.notna(row[fourth_col_name]):
                            component = str(row[fourth_col_name]).strip()
                            result_rows[key]['components'].add(component)
                        result_rows[key]['files'].add(row['source_file'])
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
                processed_rows = []
                for key, data in result_rows.items():
                    row_data = data['row'][:4]  # –ü–µ—Ä–≤—ã–µ 4 —Å—Ç–æ–ª–±—Ü–∞
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
                    if data['components']:
                        combined_components = ', '.join(sorted(data['components']))
                    else:
                        combined_components = ''
                    
                    # –ó–∞–º–µ–Ω—è–µ–º —á–µ—Ç–≤–µ—Ä—Ç—ã–π —Å—Ç–æ–ª–±–µ—Ü –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                    if len(row_data) > 3:
                        row_data[3] = combined_components
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    if len(data['row']) > 4:
                        row_data.extend(data['row'][4:])
                    
                    processed_rows.append(row_data)
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
                columns = list(merged_df.columns)
                result_df = pd.DataFrame(processed_rows, columns=columns)
                
            else:
                self.log("‚ÑπÔ∏è –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ—Å—Ç–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å—Ç—å")
                result_df = merged_df.drop(columns=['source_file'])  # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            out_path = os.path.join(folder, "merged_deduplicated.xlsx")
            
            # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            if 'source_file' in result_df.columns:
                result_df = result_df.drop(columns=['source_file'])
            
            result_df.to_excel(out_path, index=False)
            
            self.log(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")
            self.log(f"üìà –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(result_df)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if len(result_df) > 0:
                self.log("üìã –ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏):")
                for i in range(min(3, len(result_df))):
                    row = result_df.iloc[i]
                    cve = row.iloc[0] if pd.notna(row.iloc[0]) else "N/A"
                    component = row.iloc[3] if len(row) > 3 and pd.notna(row.iloc[3]) else "N/A"
                    self.log(f"  {i+1}. {cve} -> –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {component}")
            
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
            import traceback
            self.log(f"‚ùå –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")

    def parse_dpkg_line(self, line):
        parts = line.strip().split()
        if len(parts) >= 3 and parts[0] == 'ii':
            pkg = parts[1]
            ver_full = parts[2]
            ver = ver_full.split('-')[0]
            # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π CPE-—Å—Ç—Ä–æ–∫—É (–≤–µ–Ω–¥–æ—Ä –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, —Å—Ç–∞–≤–∏–º '*')
            return f"cpe:2.3:a:*:{pkg}:{ver}"
        return None

    def search_cves_in_file(self, cpe_list, json_path):
        matches = []
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for item in data.get("CVE_Items", []):
                nodes = item.get("configurations", {}).get("nodes", [])
                for node in nodes:
                    for cpe_match in node.get("cpe_match", []):
                        cpe_uri = cpe_match.get("cpe23Uri", "")
                        for cpe_query in cpe_list:
                            if cpe_query in cpe_uri:
                                cve_id = item["cve"]["CVE_data_meta"]["ID"]
                                matches.append((cpe_query, cve_id))
                                break
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {json_path}: {e}")
        return matches

    def start_cve_offline_search(self):
        # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏–∑ GUI
        threading.Thread(target=self.cve_offline_search, daemon=True).start()

    def cve_offline_search(self):
        self.log("üìÇ –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≤—ã–≤–æ–¥–æ–º dpkg -l")
        dpkg_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª dpkg -l",
            filetypes=[("–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã", "*.txt *.log *.out"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")]
        )
        if not dpkg_path:
            self.log("‚ùó –§–∞–π–ª dpkg –Ω–µ –≤—ã–±—Ä–∞–Ω, –æ—Ç–º–µ–Ω–∞.")
            return

        self.log("üîç –ß–∏—Ç–∞—é dpkg -l –∏ —Ñ–æ—Ä–º–∏—Ä—É—é CPE...")
        with open(dpkg_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        cpe_list = list(filter(None, (self.parse_dpkg_line(line) for line in lines)))
        self.log(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(cpe_list)} CPE")

        self.log("üìÇ –í—ã–±–µ—Ä–∏—Ç–µ JSON —Ñ–∞–π–ª—ã —Å –±–∞–∑–æ–π CVE")
        json_paths = filedialog.askopenfilenames(
            title="–í—ã–±–µ—Ä–∏—Ç–µ JSON —Ñ–∞–π–ª—ã CVE",
            filetypes=[("JSON —Ñ–∞–π–ª—ã", "*.json"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")]
        )
        if not json_paths:
            self.log("‚ùó JSON —Ñ–∞–π–ª—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã, –æ—Ç–º–µ–Ω–∞.")
            return

        self.log(f"‚ö° –ó–∞–ø—É—Å–∫–∞—é –ø–æ–∏—Å–∫ CVE –≤ {len(json_paths)} —Ñ–∞–π–ª–∞—Ö —Å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å—é...")
        matches = []
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(self.search_cves_in_file, cpe_list, path) for path in json_paths]
            for future in as_completed(futures):
                res = future.result()
                matches.extend(res)
                self.log(f"üîé –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª, –Ω–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {len(res)}")

        if not matches:
            self.log("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return

        self.log(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {len(matches)}")

        save_path = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã", "*.txt"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")],
            title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞"
        )
        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                for cpe, cve in matches:
                    f.write(f"{cpe} ‚Üí {cve}\n")
            self.log(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {save_path}")
        else:
            self.log("‚ö†Ô∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
    def search_vuln_by_packages(self):
        txt_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ .txt —Ñ–∞–π–ª —Å –ø–∞–∫–µ—Ç–∞–º–∏ (—Ñ–æ—Ä–º–∞—Ç: –∏–º—è;–≤–µ—Ä—Å–∏—è)",
            filetypes=[("–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã", "*.txt"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")]
        )
        if not txt_path:
            self.log("‚ùó –§–∞–π–ª —Å –ø–∞–∫–µ—Ç–∞–º–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω.")
            return

        packages = {}
        with open(txt_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split(';')
                if len(parts) == 2:
                    name, version = parts
                    packages[name.strip()] = version.strip()

        self.log(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(packages)} –ø–∞–∫–µ—Ç–æ–≤")

        vuln_counts = {pkg: 0 for pkg in packages}

        for entry in self.file_entries:
            scan_type = entry.get_selected_type()
            if scan_type not in ["fstec", "astra"]:
                continue
            try:
                with open(entry.get_path(), encoding='utf-8') as f:
                    soup = BeautifulSoup(f, 'html.parser')

                rows = soup.find_all('tr', class_='table-vulnerabilities__row')

                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) >= 3 and '–ü–û/–ü–∞–∫–µ—Ç' in cols[0].get_text(strip=True):
                        pkg_name = cols[2].get_text(strip=True)
                        if pkg_name in packages:
                            vuln_counts[pkg_name] += 1
            except Exception as e:
                self.log(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {entry.get_path()}: {e}")

        save_dir = self.save_path_var.get().strip()
        if not save_dir:
            self.log("‚ùó –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω.")
            return

        out_path = os.path.join(os.path.dirname(save_dir), "—É—è–∑–≤–∏–º–æ—Å—Ç–∏ –ø–æ –ø–∞–∫–µ—Ç–∞–º.xlsx")
        df_out = pd.DataFrame(list(vuln_counts.items()), columns=["–ü–∞–∫–µ—Ç", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π"])
        df_out.to_excel(out_path, index=False)
        self.log(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")

    def reset_all(self):
        """–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –æ—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏"""
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        for entry in self.file_entries:
            entry.frame.destroy()
        self.file_entries = []
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for tmp_file in self.temp_files:
            try:
                if os.path.exists(tmp_file):
                    os.unlink(tmp_file)
            except Exception:
                pass
        self.temp_files = []
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        self.closed_path_var.set("")
        self.desc_path_var.set("")
        
        # –û—á–∏—â–∞–µ–º –ª–æ–≥–∏
        self.log_text.config(state='normal')
        self.log_text.delete('1.0', tk.END)
        self.log_text.config(state='disabled')
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        self.progress['value'] = 0
        
        self.log("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –∏ –ª–æ–≥–∏ —Å–±—Ä–æ—à–µ–Ω—ã. –ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å –Ω–æ–≤—ã–µ.")






if __name__ == "__main__":
    root = TkinterDnD.Tk()
    app = VulnParserApp(root)
    root.geometry("1400x1000")
    root.mainloop()